---
title: "DeepSeek R1"
description: "DeepSeek-R1 is a state-of-the-art reasoning model, providing high-quality intelligence with built-in chain-of-thought processing."
---

import { ModelInfo } from '/snippets/model-info.jsx';
import { deepseekR1Data } from '/snippets/model-data.jsx';

<ModelInfo {...deepseekR1Data} />

## Quick Integration

<CodeGroup>
```bash cURL
curl https://api.neosantara.xyz/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_NEOSANTARA_API_KEY" \
  -d '{
    "model": "deepseek-r1",
    "messages": [
      { "role": "user", "content": "Explain the steps to solve 15 * 24 + 133" }
    ],
    "thinking": { "type": "enabled", "budget_tokens": 2048 }
  }'
```

```python Python
from openai import OpenAI

client = OpenAI(
    base_url="https://api.neosantara.xyz/v1",
    api_key="YOUR_NEOSANTARA_API_KEY"
)

response = client.chat.completions.create(
    model="deepseek-r1",
    messages=[
        {"role": "user", "content": "Explain the steps to solve 15 * 24 + 133"}
    ],
    extra_body={
        "thinking": { "type": "enabled", "budget_tokens": 2048 }
    }
)

# Access the thought process
print(response.choices[0].message.reasoning_content)
# Access the final answer
print(response.choices[0].message.content)
```

```javascript Node.js
import OpenAI from "openai";

const openai = new OpenAI({
  baseURL: "https://api.neosantara.xyz/v1",
  apiKey: "YOUR_NEOSANTARA_API_KEY"
});

const completion = await openai.chat.completions.create({
  messages: [{ role: "user", content: "Explain the steps to solve 15 * 24 + 133" }],
  model: "deepseek-r1",
  thinking: { type: "enabled", budget_tokens: 2048 }
});

console.log(completion.choices[0].message.reasoning_content);
console.log(completion.choices[0].message.content);
```

</CodeGroup>
