---
title: 'Create a Message'
description: '> Send a structured list of input messages with text and/or image content, and the model will generate the next message in the conversation.'
---

## Overview

The `/v1/messages` endpoint implements the [**Anthropic Claude API specification**](https://platform.claude.com/docs/en/api/messages/create).

## Parameters

<ParamField path="model" type="string" required>
The model ID to use for the request.

**Example:** `"garda-beta-mini"`, `"nusantara-base"`

</ParamField>

<ParamField path="messages" type="array[object]" required>
Array of message objects with alternating user/assistant roles.

**Constraints:**
  - Must be non-empty array
  - Maximum 100,000 messages
  - First message must have role `"user"`
  - Messages must alternate between `"user"` and `"assistant"` roles (strict)
  - Cannot have consecutive messages with same role
  
**Valid Structure:**
```json
{
  "messages": [
    {
      "role": "user",
      "content": "What is the capital of France?"
    },
    {
      "role": "assistant",
      "content": "The capital of France is Paris."
    },
    {
      "role": "user",
      "content": "Tell me more about it."
    }
  ]
}
```

**Message Content Types:**
- **Text:** `{"type": "text", "text": "..."}`
- **Image URL:** `{"type": "image_url", "image_url": {"url": "https://..."}}`
- **Document:** `{"type": "document", "..."}`
- **String Content:** Direct string (converted to text)

</ParamField>

<ParamField path="max_tokens" type="integer" required>
Maximum tokens for the response.

**Range:** `≥ 1`

</ParamField>

<ParamField path="temperature" type="number" default="1.0">
Controls randomness. Higher = more random, Lower = more deterministic.

**Range:** `0.0 - 1.0`

</ParamField>

<ParamField path="stream" type="boolean" default="false">
Enable streaming responses (Server-Sent Events format).

**Streaming Events:**
- `message_start` - Initial message metadata
- `content_block_start` - Text block starts
- `content_block_delta` - Text chunk delta
- `content_block_stop` - Text block ends
- `message_delta` - Message metadata update
- `message_stop` - Stream complete

</ParamField>

<ParamField path="top_p" type="number" default="1.0">
Nucleus sampling - cumulative probability threshold.

**Range:** `0.0 - 1.0`

</ParamField>

<ParamField path="top_k" type="number">
Sample from top K tokens by probability.

**Range:** `> 0`

</ParamField>

<ParamField path="stop_sequences" type="array[string]" default="[]">
Sequences where generation stops.

**Max Items:** Typically 5 sequences

</ParamField>

<ParamField path="system" type="string | array[object]">
System prompt/instructions for the model.

**Format:**
  - **String:** Direct system message
  - **Array:** Array of system blocks `[{"type": "text", "text": "..."}]`

</ParamField>

<ParamField path="tools" type="array[object]" default="[]">
Array of tool/function definitions.

**Format:** Standard Anthropic tool format
</ParamField>

<ParamField path="tool_choice" type="string" default="auto">
How to handle tool selection.

**Options:** `"auto"`, `"any"`, `{"type": "tool", "name": "..."}`

</ParamField>

<ParamField path="metadata" type="object" default="{}">
Custom metadata for tracking/logging.

</ParamField>

<ParamField path="service_tier" type="string" default="auto">
Which service tier to use.

**Options:** `"auto"`, `"standard_only"`

</ParamField>

<ParamField path="thinking" type="object">
Enable extended thinking mode.

**Structure:**
```json
{
  "type": "enabled",
  "budget_tokens": 5000
}
```

**Constraints:**
  - `budget_tokens` must be `≥ 1024`
  - `budget_tokens` must be `< max_tokens`

</ParamField>

## Response

<ResponseField name="id" type="string">
The unique identifier for the message.
</ResponseField>

<ResponseField name="type" type="string">
The type of the response, always "message".
</ResponseField>

<ResponseField name="role" type="string">
The role of the responder, always "assistant".
</ResponseField>

<ResponseField name="model" type="string">
The model used for the response.
</ResponseField>

<ResponseField name="stop_reason" type="string">
The reason generation stopped, e.g., "end_turn".
</ResponseField>

<ResponseField name="stop_sequence" type="string | null">
The stop sequence that triggered the end, if any.
</ResponseField>

<ResponseField name="content" type="array[object]">
The generated content.

<ResponseField name="type" type="string">
The type of content block, e.g., "text".
</ResponseField>

<ResponseField name="text" type="string">
The text content.
</ResponseField>

</ResponseField>

<ResponseField name="usage" type="object">
Token usage statistics.

<ResponseField name="input_tokens" type="integer">
Number of input tokens.
</ResponseField>

<ResponseField name="output_tokens" type="integer">
Number of output tokens.
</ResponseField>

<ResponseField name="cache_creation_input_tokens" type="integer">
Cache creation input tokens.
</ResponseField>

<ResponseField name="cache_read_input_tokens" type="integer">
Cache read input tokens.
</ResponseField>

</ResponseField>

### Streaming Response (SSE Format)
```
event: message_start
data: {"type": "message_start", "message": {...}}

event: content_block_start
data: {"type": "content_block_start", "content_block": {"type": "text", "text": ""}}

event: content_block_delta
data: {"type": "content_block_delta", "delta": {"type": "text_delta", "text": "The"}}

event: content_block_delta
data: {"type": "content_block_delta", "delta": {"type": "text_delta", "text": " capital"}}

event: message_stop
data: {"type": "message_stop"}
```

## Error Handling

### Common Error Codes

| Code | Status | Description |
|------|--------|-------------|
| `missing_model` | 400 | Model parameter not provided |
| `model_not_found` | 404 | Model doesn't exist |
| `missing_messages` | 400 | Messages array not provided |
| `invalid_message_role` | 400 | Invalid role or non-alternating |
| `too_many_messages` | 400 | Messages exceed 100,000 limit |
| `invalid_temperature` | 400 | Temperature outside 0.0-1.0 range |
| `context_window_exceeded` | 400 | Input tokens exceed context window |
| `insufficient_context_for_output` | 400 | Not enough context for response |

### Error Response Format

<Response>

<ResponseField name="error" type="object">

<ResponseField name="message" type="string">
The error message.
</ResponseField>

<ResponseField name="type" type="string">
The type of error, e.g., "invalid_request_error".
</ResponseField>

<ResponseField name="code" type="string">
The error code.
</ResponseField>

</ResponseField>

</Response>

## Request Examples

<AccordionGroup>

<Accordion title="Simple Chat">

```bash
curl https://api.neosantara.xyz/v1/messages \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $API_KEY" \
  -d '{
    "model": "nusantara-base",
    "max_tokens": 1024,
    "messages": [
      {"role": "user", "content": "What is 2+2?"}
    ]
  }'
```

</Accordion>

<Accordion title="With System Prompt">

```bash
curl https://api.neosantara.xyz/v1/messages \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $API_KEY" \
  -d '{
    "model": "nusantara-base",
    "max_tokens": 1024,
    "system": "You are a Python expert.",
    "messages": [
      {"role": "user", "content": "Write a hello world function."}
    ]
  }'
```

</Accordion>

<Accordion title="Streaming with Temperature">

```bash
curl https://api.neosantara.xyz/v1/messages \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $API_KEY" \
  -d '{
    "model": "nusantara-base",
    "max_tokens": 2048,
    "temperature": 0.8,
    "stream": true,
    "messages": [
      {"role": "user", "content": "Tell me a creative story."}
    ]
  }'
```

</Accordion>

<Accordion title="Function Calling">

```bash
curl https://api.neosantara.xyz/v1/messages \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $API_KEY" \
  -d '{
    "model": "nusantara-base",
    "max_tokens": 1024,
    "tools": [
      {
        "name": "calculate",
        "description": "Calculate math expression",
        "input_schema": {
          "type": "object",
          "properties": {
            "expression": {"type": "string"}
          },
          "required": ["expression"]
        }
      }
    ],
    "messages": [
      {"role": "user", "content": "What is 15 * 3?"}
    ]
  }'
```

</Accordion>

<Accordion title="Extended Thinking">

```bash
curl https://api.neosantara.xyz/v1/messages \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $API_KEY" \
  -d '{
    "model": "nusantara-base",
    "max_tokens": 10000,
    "thinking": {
      "type": "enabled",
      "budget_tokens": 5000
    },
    "messages": [
      {"role": "user", "content": "Solve this complex problem..."}
    ]
  }'
```

</Accordion>

</AccordionGroup>

## Compatibility

| Parameter | Required | Type | Claude SDK | Default | Notes |
|-----------|----------|------|-----------|---------|-------|
| `model` | ✅ Yes | string | ✅ Yes | - | Use Neosantara model instead |
| `messages` | ✅ Yes | array | ✅ Yes | - | Alternating user/assistant |
| `max_tokens` | ✅ Yes | integer | ✅ Yes | - | Min 1 token |
| `temperature` | ❌ No | number | ✅ Yes | 1.0 | Range: 0.0-1.0 |
| `stream` | ❌ No | boolean | ✅ Yes | false | SSE format |
| `top_p` | ❌ No | number | ✅ Yes | 1.0 | Range: 0.0-1.0 |
| `top_k` | ❌ No | number | ✅ Yes | - | Must be > 0 |
| `stop_sequences` | ❌ No | array | ✅ Yes | [] | Max 5 sequences |
| `system` | ❌ No | string/array | ✅ Yes | - | Separate parameter |
| `tools` | ❌ No | array | ✅ Yes | [] | Function definitions |
| `tool_choice` | ❌ No | string | ✅ Yes | "auto" | auto/any/specific |
| `metadata` | ❌ No | object | ✅ Yes | {} | Custom tracking |
| `service_tier` | ❌ No | string | ✅ Yes | "auto" | auto/standard_only |
| `thinking` | ❌ No | object | ✅ Yes | - | Extended thinking mode |