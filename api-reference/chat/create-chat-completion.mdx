---
title: 'Create Chat Completion' 
api: 'POST /v1/chat/completions' 
playground: 'simple' 
authMethod: 'bearer'
---

<Card icon="key" href="https://app.neosantara.xyz/api-keys" title="Get your free API key" horizontal>
Start with **10,000 Monthly Token Limit** on our Free Plan. **No credit card required.** Your tokens automatically reset on the 1st of each month.
</Card>

<ParamField path="messages" type="array" required>
A list of messages comprising the conversation so far. Each message object requires a `role` (system, user, assistant, or tool) and `content`.
</ParamField>

<ParamField path="model" type="string" required>
ID of the model to use (e.g., `gpt-4o`, `nusantara-base`). See [`/v1/models`](/api-reference/models/list-available-models).
</ParamField>

<ParamField path="max_tokens" type="integer">
The maximum number of tokens to generate in the chat completion.
</ParamField>

<ParamField path="temperature" type="number" default="1">
What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.
</ParamField>

<ParamField path="top_p" type="number" default="1">
An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass.
</ParamField>

<ParamField path="stream" type="boolean" default="false">
If set, partial message deltas will be sent, like in ChatGPT.
</ParamField>

<ParamField path="stop" type="string or array">
Up to 4 sequences where the API will stop generating further tokens.
</ParamField>

## Returns

<ResponseField name="id" type="string">
A unique identifier for the chat completion.
</ResponseField>

<ResponseField name="object" type="string">
The object type, which is always `chat.completion`.
</ResponseField>

<ResponseField name="created" type="integer">
The Unix timestamp (in seconds) of when the chat completion was created.
</ResponseField>

<ResponseField name="model" type="string">
The model used for the chat completion.
</ResponseField>

<ResponseField name="choices" type="array">
A list of chat completion choices. Can be more than one if `n` is greater than 1.

<Expandable title="choices properties">
<ResponseField name="index" type="integer">
The index of the choice in the list of choices.
</ResponseField>

<ResponseField name="message" type="object">
  A chat completion message generated by the model.
</ResponseField>

<ResponseField name="finish_reason" type="string">
  The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence, `length` if the maximum number of tokens specified in the request was reached, `tool_calls` if the model called a tool, or `content_filter` if content was omitted due to a flag from our content filters.
</ResponseField>

</Expandable>
</ResponseField>

<ResponseField name="usage" type="object">
Usage statistics for the completion request.

<Expandable title="usage properties">
<ResponseField name="prompt_tokens" type="integer">
Number of tokens in the prompt.
</ResponseField>

<ResponseField name="completion_tokens" type="integer">
  Number of tokens in the generated completion.
</ResponseField>

<ResponseField name="total_tokens" type="integer">
  Total number of tokens used in the request (prompt + completion).
</ResponseField>

</Expandable>
</ResponseField>

## Return Examples

```json Response 200
{
  "id": "chatcmpl-123",
  "object": "chat.completion",
  "created": 1677652288,
  "model": "gpt-4o",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "Hello there, how may I assist you today?"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 9,
    "completion_tokens": 12,
    "total_tokens": 21
  }
}
```