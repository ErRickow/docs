---
title: 'OpenAI Compatibility'
description: 'Use the official OpenAI SDK to interact with Neosantara AI.'
---

Neosantara AI provides two primary ways to interact with our models using the official OpenAI SDK:

1.  **Chat Completions (`/v1/chat/completions`)**: fully compatible with OpenAI's standard API. Ideal for drop-in replacement in existing apps.
2.  **Responses API (`/v1/responses`)**: An enhanced, modern API designed by Neosantara that simplifies conversation state management and inputs.

<Note>
  You can use the official OpenAI SDK for **both** endpoints. No special Neosantara SDK is required.
</Note>

<View title="Responses API (Enhanced)" icon="bolt">
## Responses API (Enhanced)

The **Responses API** (`/v1/responses`) is a modern alternative to Chat Completions. It simplifies the request structure (using `input` instead of a complex `messages` array) and supports **Server-Side State** (Conversation History).

### Why use it?
*   **Simpler Input**: Just send a string `input` for simple turns.
*   **Stateful Conversations**: Use `store: true` and `previous_response_id` to have the server remember context. You don't need to send the full history every time.
*   **Unified Output**: Returns a standardized `output` array.

### Quick Start

Since this is a custom endpoint, you access it using the SDK's generic `post` method.

<CodeGroup>
```python Python
from openai import OpenAI

client = OpenAI(
    base_url="https://api.neosantara.xyz/v1",
    api_key="<YOUR_API_KEY>"
)

# Accessing /v1/responses via raw request
response = client.post(
    "/responses",
    body={
        "model": "nusantara-base",
        "input": "Who are you?",
        "store": True  # Enable conversation history
    }
).cast_to(dict) # Cast to dict for easier access

# Response structure: { "output": [ { "content": [ { "text": "..." } ] } ] }
print(response["output"][0]["content"][0]["text"])

# Save the ID for the next turn!
print(f"Response ID: {response['id']}")
```

```javascript Node.js
import OpenAI from "openai";

const openai = new OpenAI({
  baseURL: "https://api.neosantara.xyz/v1",
  apiKey: "<YOUR_API_KEY>",
});

async function main() {
  // Accessing /v1/responses via custom fetch or generic method
  const response = await openai.post("/responses", {
    model: "nusantara-base",
    input: "Who are you?",
    store: true,
  });

  // Response structure: { output: [ { content: [ { text: "..." } ] } ] }
  console.log(response.output[0].content[0].text);
  
  // Save the ID for the next turn!
  console.log(`Response ID: ${response.id}`);
}

main();
```
</CodeGroup>
</View>

<View title="Chat Completions API (Standard)" icon="message-circle-dots">
## Chat Completions API (Standard)

This is the standard OpenAI format. Use this if you are migrating an existing application (e.g., LangChain, AutoGen) and want zero code changes.

### Quick Start

<CodeGroup>
```python Python
from openai import OpenAI

# 1. Point to Neosantara's Base URL
client = OpenAI(
    base_url="https://api.neosantara.xyz/v1",
    api_key="<YOUR_API_KEY>"
)

# 2. Use standard Chat Completions
response = client.chat.completions.create(
    model="nusantara-base",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Hello!"}
    ],
    stream=False
)

print(response.choices[0].message.content)
```

```javascript Node.js
import OpenAI from "openai";

const openai = new OpenAI({
  baseURL: "https://api.neosantara.xyz/v1",
  apiKey: "<YOUR_API_KEY>",
});

async function main() {
  const completion = await openai.chat.completions.create({
    messages: [{ role: "user", content: "Hello world" }],
    model: "nusantara-base",
  });

  console.log(completion.choices[0].message.content);
}

main();
```
</CodeGroup>
</View>

## Feature Comparison

| Feature | Chat Completions (`/chat/completions`) | Responses API (`/responses`) |
| :--- | :--- | :--- |
| **Compatibility** | 100% OpenAI Compatible | Neosantara Enhanced |
| **Input Format** | `messages: [{role, content}, ...]` | `input: "text"` or `messages` |
| **State Management** | Client-side (must send full history) | **Server-side** (via `previous_response_id`) |
| **JSON Mode** | `response_format: { type: "json_object" }` | `response_format` + `json_schema` |
| **Streaming** | Supported | Supported |
| **Tools/Functions** | Supported | Supported |

## Supported Parameters

Neosantara filters unsupported parameters to prevent errors.

| Parameter | Supported? | Notes |
| :--- | :---: | :--- |
| `model` | ✅ | Required. See [Models](/en/models-overview). |
| `messages` | ✅ | Primary input for Chat Completions. |
| `input` | ✅ | Primary input for Responses API. |
| `stream` | ✅ | Server-sent events (SSE). |
| `temperature` | ✅ | Default: 0.7 |
| `top_p` | ✅ | Default: 1.0 |
| `max_tokens` | ✅ | |
| `tools` | ✅ | Function calling supported. |
| `response_format` | ✅ | |
| `reasoning` | ✅ | **Neosantara Exclusive**. Set effort: `low`, `medium`, `high`. |
| `n` | ❌ | Only 1 choice supported. |
| `logprobs` | ❌ | Not currently supported. |
