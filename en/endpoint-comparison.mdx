---
title: "API Endpoint Comparison"
description: "Compare Neosantara AI API endpoints to choose the best one for your use case."
---

Neosantara AI provides multiple API endpoints, each optimized for different use cases. This guide helps you choose the right endpoint and understand the key differences between them.

## Quick Comparison

| Feature | OpenAI Compatible | Anthropic Compatible | Responses API |
| ---

------ | ------------------- | --------------------- | ---------------- |
| **Endpoint** | `/v1/chat/completions` | `/anthropic/v1/messages` | `/v1/responses` |
| **State Management** | âŒ Stateless | âŒ Stateless | âœ… via `previous_response_id` |
| **Input Format** | `messages` array | `messages` array | `string` or array |
| **Tool Calling** | âœ… Standard format | âœ… Tool schema | âœ… Native & Enhanced |
| **Streaming** | âœ… SSE | âœ… SSE | âœ… SSE |
| **Authentication** | Bearer token | Bearer token | Bearer token |
| **Migration Effort** | ğŸŸ¢ Minimal | ğŸŸ¢ Low | ğŸŸ¢ Low |
| **Best For** | Existing OpenAI apps | Anthropic ecosystem | New applications |

<Tip>
  **Recommendation**: Use Responses API for new applications (utilizing `previous_response_id` for state), OpenAI Compatible for existing OpenAI-based apps, and Anthropic Compatible for Anthropic ecosystem integration.
</Tip>

## Detailed Feature Matrix

### Core Functionality

| Feature | OpenAI Compatible | Anthropic Compatible | Responses API |
| --------- | ------------------- | --------------------- | ---------------- |
| Chat completion | âœ… | âœ… | âœ… |
| Tool/function calling | âœ… | âœ… | âœ… |
| Streaming responses | âœ… | âœ… | âœ… |
| Image input (vision) | âœ… | âœ… | âœ… |
| System prompts | âœ… | âœ… | âœ… |
| Temperature control | âœ… | âœ… | âœ… |
| Token limits | âœ… | âœ… | âœ… |

### Advanced Features

| Feature | OpenAI Compatible | Anthropic Compatible | Responses API |
| --------- | ------------------- | --------------------- | ---------------- |
| Conversation state management | âŒ | âŒ | âœ… `previous_response_id` |
| Automatic context handling | âŒ | âŒ | âœ… |
| Unified output format | âŒ | âŒ | âœ… |
| Extended thinking mode | âŒ | âŒ | âœ… |
| Built-in retry logic | âŒ | âŒ | âœ… |

### Development Experience

| Aspect | OpenAI Compatible | Anthropic Compatible | Responses API |
| --------- | ------------------- | --------------------- | ---------------- |
| SDK support | ğŸŸ¢ Excellent | ğŸŸ¢ Excellent | ğŸŸ¡ Limited |
| Library compatibility | ğŸŸ¢ Universal | ğŸŸ¡ Anthropic-specific | ğŸŸ¡ Limited |
| Learning curve | ğŸŸ¢ Low | ğŸŸ¡ Medium | ğŸŸ¡ Low |
| Debugging ease | ğŸŸ¢ Standard | ğŸŸ¢ Standard | ğŸŸ¢ Improved |
| Error handling | ğŸŸ¢ Standard | ğŸŸ¢ Standard | ğŸŸ¢ Improved |

## Use Case Recommendations

### Choose OpenAI Compatible If

- âœ… **Migrating existing OpenAI application**
- âœ… **Using libraries like LangChain, LlamaIndex**
- âœ… **Need maximum SDK compatibility**
- âœ… **Team already knows OpenAI format**
- âœ… **Quick integration priority**

**Example Use Cases:**

```python icon="python"
# Perfect for existing OpenAI apps
from openai import OpenAI

client = OpenAI(base_url="https://api.neosantara.xyz/v1")
response = client.chat.completions.create(
    model="nusantara-base",
    messages=[{"role": "user", "content": "Hello!"}]
)
```

### Choose Anthropic Compatible If

- âœ… **Using Claude Code or Anthropic SDKs**
- âœ… **Need advanced tool calling capabilities**
- âœ… **Prefer Anthropic's message format**
- âœ… **Building with Claude ecosystem tools**
- âœ… **Require sophisticated reasoning modes**

**Example Use Cases:**

```python icon="python"
# Best for Anthropic ecosystem
import anthropic

client = anthropic.Anthropic(base_url="https://api.neosantara.xyz/anthropic")
message = client.messages.create(
    model="nusantara-base",
    messages=[{"role": "user", "content": "Hello!"}]
)
```

### Choose Responses API If

- âœ… **Starting a new application**
- âœ… **Want stateful conversations**
- âœ… **Need simplified input/output**
- âœ… **Building agent-like applications**
- âœ… **Prefer modern API design**

**Example Use Cases:**

```python icon="python"
# Ideal for new applications
from openai import OpenAI

client = OpenAI(base_url="https://api.neosantara.xyz/v1")
response = client.responses.create(
    model="nusantara-base",
    input="Hello! Tell me about yourself.",
    store=True  # Store response for future continuation
)
```

## Migration Guides

### From OpenAI Compatible to Responses API

```python icon="python"
# Before (OpenAI Compatible)
response = client.chat.completions.create(
    model="nusantara-base",
    messages=[
        {"role": "system", "content": "You are helpful."},
        {"role": "user", "content": "Hello!"}
    ],
    tools=[...],
    stream=True
)

# After (Responses API)
response = client.responses.create(
    model="nusantara-base",
    input="Hello! Tell me about yourself.",
    system="You are helpful.",
    tools=[...],
    store=True,  # Enable persistence for stateful turns
    stream=True
)

# Access simplified output
print(response.output_text)
```

### From Anthropic Compatible to Responses API

```python icon="python"
# Before (Anthropic Compatible)
message = client.messages.create(
    model="nusantara-base",
    system="You are helpful.",
    messages=[
        {"role": "user", "content": [{"type": "text", "text": "Hello!"}]}
    ],
    tools=[...]
)

# After (Responses API)
response = client.responses.create(
    model="nusantara-base",
    input="Hello! Tell me about yourself.",
    system="You are helpful.",
    tools=[...],
    store=True
)

# Access content directly
print(response.output_text)
```

## Performance Considerations

### Latency Comparison

<Note>
  Latency values are typical estimates for standard payloads in the Southeast Asia region. Actual performance varies significantly based on model size, prompt complexity, and network conditions.
</Note>

| Endpoint | Average Latency | P95 Latency | Notes |
| --------- | ------------------ | -------------- | ------- |
| OpenAI Compatible | ~200ms | ~400ms | Consistent performance |
| Anthropic Compatible | ~220ms | ~450ms | Slightly higher for tool parsing |
| Responses API | ~180ms | ~350ms | Optimized for new apps |

### Throughput Characteristics

| Feature | OpenAI Compatible | Anthropic Compatible | Responses API |
| --------- | ------------------- | --------------------- | ---------------- |
| Concurrent requests | âœ… High | âœ… High | âœ… High |
| Streaming efficiency | ğŸŸ¢ Standard | ğŸŸ¢ Standard | ğŸŸ¢ Optimized |
| Memory usage | ğŸŸ¡ Medium | ğŸŸ¡ Medium | ğŸŸ¢ Lower with state |
| Connection reuse | ğŸŸ¢ Standard | ğŸŸ¢ Standard | ğŸŸ¢ Improved |

### Rate Limits

| Endpoint | Rate Limiting | Burst Capacity |
| --------- | ---------------- | ----------------- |
| OpenAI Compatible | Per-model, per-key | Standard |
| Anthropic Compatible | Per-model, per-key | Standard |
| Responses API | Per-model, per-key | Enhanced via store |

## Code Examples by Use Case

### Chat Application

<CodeGroup>

```python icon="python"
from openai import OpenAI

client = OpenAI(base_url="https://api.neosantara.xyz/v1")

def chat_with_history(message_history, new_message):
    response = client.chat.completions.create(
        model="nusantara-base",
        messages=message_history + [new_message]
    )
    return response.choices[0].message.content
```

```python icon="python"
import anthropic

client = anthropic.Anthropic(base_url="https://api.neosantara.xyz/anthropic")

def chat_with_history(message_history, new_message):
    response = client.messages.create(
        model="nusantara-base",
        messages=message_history + [new_message]
    )
    return response.content[0].text
```

```python icon="python"
from openai import OpenAI

client = OpenAI(base_url="https://api.neosantara.xyz/v1")

def chat_stateful(user_input, previous_id=None):
    response = client.responses.create(
        model="nusantara-base",
        input=user_input,
        previous_response_id=previous_id,
        store=True
    )
    return response.output_text, response.id
```
</CodeGroup>

### Tool Calling

<CodeGroup>

```python icon="python"
tools = [{
    "type": "function",
    "function": {
        "name": "get_weather",
        "description": "Get weather",
        "parameters": {
            "type": "object",
            "properties": {"location": {"type": "string"}},
            "required": ["location"]
        }
    }
}]

response = client.chat.completions.create(
    model="nusantara-base",
    messages=[{"role": "user", "content": "What's the weather?"}],
    tools=tools
)

tool_calls = response.choices[0].message.tool_calls
```

```python icon="python"
tools = [{
    "name": "get_weather",
    "description": "Get weather",
    "input_schema": {
        "type": "object",
        "properties": {"location": {"type": "string"}},
        "required": ["location"]
    }
}]

response = client.messages.create(
    model="nusantara-base",
    messages=[{"role": "user", "content": "What's the weather?"}],
    tools=tools
)

tool_use = next(c for c in response.content if c.type == "tool_use")
```

```python icon="python"
tools = [{
    "type": "function",
    "name": "get_weather",
    "description": "Get weather",
    "parameters": {
        "type": "object",
        "properties": {"location": {"type": "string"}},
        "required": ["location"]
    }
}]

response = client.responses.create(
    model="nusantara-base",
    input="What's the weather?",
    tools=tools,
    store=True
)

tool_calls = [item for item in response.output if item.type == "function_call"]
```
</CodeGroup>

## Decision Framework

Use this decision tree to choose the right endpoint:

```text
Start: Are you building a new application?
â”œâ”€â”€ Yes â†’ Do you want stateful conversations?
â”‚   â”œâ”€â”€ Yes â†’ Use Responses API
â”‚   â””â”€â”€ No â†’ Do you prefer Anthropic SDK?
â”‚       â”œâ”€â”€ Yes â†’ Use Anthropic Compatible
â”‚       â””â”€â”€ No â†’ Use OpenAI Compatible
â””â”€â”€ No â†’ Are you migrating from OpenAI?
    â”œâ”€â”€ Yes â†’ Use OpenAI Compatible
    â””â”€â”€ No â†’ Are you using Anthropic SDK?
        â”œâ”€â”€ Yes â†’ Use Anthropic Compatible
        â””â”€â”€ No â†’ Consider Responses API for simplicity
```

## Best Practices

### General Recommendations

1. **Use environment variables** for API keys
2. **Implement proper error handling** for all endpoints
3. **Use streaming** for real-time applications
4. **Set appropriate timeouts** for your use case
5. **Monitor token usage** across all endpoints

### Endpoint-Specific Tips

**OpenAI Compatible:**

- Maintain message history on client side
- Use standard function calling format
- Leverage existing OpenAI libraries

**Anthropic Compatible:**

- Use tool schema format
- Leverage thinking mode for complex tasks
- Use content blocks for multimodal input

**Responses API:**

- Enable `store` for state management
- Use `previous_response_id` for conversation continuation
- Leverage unified output format

## Migration Checklist

### Before Migration

- [ ] Identify current endpoint and usage patterns
- [ ] Test new endpoint with small dataset
- [ ] Plan data migration if needed
- [ ] Update authentication and base URLs

### During Migration

- [ ] Implement dual-mode support for gradual transition
- [ ] Update error handling for new response formats
- [ ] Test all functionality with new endpoint
- [ ] Update documentation and examples

### After Migration

- [ ] Monitor performance and error rates
- [ ] Update team documentation
- [ ] Remove legacy code after validation
- [ ] Update monitoring and logging

## Support Resources

<CardGroup cols={2}>
  <Card title="SDK Documentation" icon="book" href="/en/sdk">
    Detailed SDK implementation guides.
  </Card>
  
  <Card title="Error Handling" icon="exclamation-triangle" href="/en/about/errors">
    Common errors and solutions.
  </Card>
  
  <Card title="Rate Limits" icon="gauge-high" href="/en/about/rate-limits">
    Understanding rate limiting by tier.
  </Card>
  
  <Card title="Examples Repository" icon="code-branch" href="https://github.com/neosantara/examples">
    Full code examples for all endpoints.
  </Card>
</CardGroup>
