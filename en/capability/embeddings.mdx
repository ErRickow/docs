---
title: 'Embeddings'
description: '> Convert text into high-dimensional numerical vectors for various AI tasks.'
---

Embeddings are numerical representations of text that capture semantic meaning. They convert human-readable text into high-dimensional vectors that machine learning models can understand and process. These vectors enable tasks such as semantic search, recommendation systems, clustering, and anomaly detection.

## How Embeddings Work

When you send text to the embeddings endpoint, the underlying AI model processes the text and outputs a list of floating-point numbers (a vector). Texts with similar meanings will have vectors that are numerically "closer" to each other in the high-dimensional space.

The Neosantara AI API provides an [`/v1/embeddings`](/api-reference/embeddings/create-embeddings) endpoint to generate these vectors.

## Usage

To generate embeddings, send a POST request to the `/v1/embeddings` endpoint with your text input.

### Endpoint

> POST https://api.neosantara.xyz/v1/embeddings

### Request Body

```json
{
  "input": "The quick brown fox jumps over the lazy dog.",
  "model": "nusa-embedding-0001",
  "encoding_format": "float"
}
```

See [full reference](/api-reference/embeddings/create-embeddings)

### Supported Embedding Models

The Neosantara AI API supports various embedding models, often utilizing intelligent fallbacks to ensure reliability. Some of the available models include:

* **`nusa-embedding-0001`**: The primary embedding model, offering good performance for general-purpose embeddings.

### Example Response

```json
{
  "object": "list",
  "data": [
    {
      "object": "embedding",
      "embedding": [
        0.00539745,
        -0.007137805,
        0.02102179,
        -0.003181825,
        // ... (truncated for brevity)
        -0.010260487
      ],
      "index": 0
    }
  ],
  "model": "nusa-embedding-0001",
  "usage": {
    "prompt_tokens": 9,
    "total_tokens": 9
  }
}
```

## Examples with OpenAI SDK

You can generate embeddings using the OpenAI SDK by configuring its `base_url` to point to the Neosantara AI API.

<CodeGroup>
```python Py icon="python"
from openai import OpenAI

# Replace "YOUR_API_KEY" with your actual Neosantara AI API Key
client = OpenAI(
    api_key="YOUR_API_KEY",
    base_url="https://api.neosantara.xyz/v1"
)

def get_embeddings(texts: list[str], model: str = "nusa-embedding-0001"):
    """
    Generates embeddings for a list of texts using the Neosantara AI API.
    """
    print(f"Generating embeddings for model: {model}")

    try:
        response = client.embeddings.create(
            model=model,
            input=texts,
            encoding_format="float"
        )

        # The response.data contains a list of embedding objects
        # Each object has 'embedding' (the vector) and 'index'
        embeddings = [item.embedding for item in response.data]

        print(f"Generated {len(embeddings)} embeddings. Dimension: {len(embeddings[0]) if embeddings else 0}")
        print(f"Total tokens used: {response.usage.total_tokens}")

        return embeddings

    except Exception as e:
        print(f"An error occurred during embedding generation: {e}")
        return None

if __name__ == "__main__":
    example_texts = [
        "Artificial intelligence is transforming industries.",
        "Machine learning is a subset of AI.",
        "Deep learning enables neural networks."
    ]
    
    generated_vectors = get_embeddings(example_texts)

    if generated_vectors:
        print("\nFirst embedding vector (truncated):")
        print(generated_vectors[0][:10], "...") # Print first 10 elements
```

```javascript Js icon="square-js"
import OpenAI from 'openai';

// Replace "YOUR_API_KEY" with your actual Neosantara AI API Key
const client = new OpenAI({
  apiKey: "YOUR_API_KEY",
  baseURL: "https://api.neosantara.xyz/v1",
});

async function getEmbeddings(texts, model = "nusa-embedding-0001") {
  console.log(`Generating embeddings for model: ${model}`);

  try {
    const response = client.embeddings.create({
      model: model,
      input: texts,
      encoding_format: "float",
    });

    // The response.data contains a list of embedding objects
    // Each object has 'embedding' (the vector) and 'index'
    const embeddings = response.data.map(item => item.embedding);

    console.log(`Generated ${embeddings.length} embeddings. Dimension: ${embeddings[0] ? embeddings[0].length : 0}`);
    console.log(`Total tokens used: ${response.usage.total_tokens}`);

    return embeddings;

  } catch (error) {
    console.error(`An error occurred during embedding generation: ${error.message}`);
    return null;
  }
}

// Example usage
(async () => {
  const exampleTexts = [
    "Artificial intelligence is transforming industries.",
    "Machine learning is a subset of AI.",
    "Deep learning enables neural networks."
  ];
  
  const generatedVectors = await getEmbeddings(exampleTexts);

  if (generatedVectors) {
    console.log("\nFirst embedding vector (truncated):");
    console.log(generatedVectors[0].slice(0, 10), "..."); // Print first 10 elements
  }
})();
```
</CodeGroup>
