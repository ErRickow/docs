---
title: 'Llama 3.3 Nemotron Quickstart'
description: '> Get started with Neosantara AI integration of Llama 3.3 Nemotron, a powerful open reasoning model.'
---

This flexible open-weight reasoning model is designed for developers and enterprises who need transparency and customization while maintaining advanced reasoning capabilities for complex tasks.

The Llama 3.3 Nemotron model is highly capable in coding, mathematics, and agentic workflows. By default, Neosantara AI optimizes for speed and cost-efficiency by disabling reasoning. You can explicitly enable it when needed.

-----

### How to Use the API

For reasoning models that produce longer, more detailed responses, we highly recommend streaming tokens to ensure the best user experience.

#### **Default Behavior (Reasoning Off)**

By default, the model will provide a direct answer without the thought process to save tokens and reduce latency.

#### **Enabling Reasoning**

To enable step-by-step reasoning, you can use the **`thinking` parameter** (Recommended for Anthropic/OpenAI SDKs) or add `/think` to your system prompt.

```python icon="python"
from openai import OpenAI

client = OpenAI(
  base_url="https://api.neosantara.xyz/v1",
  api_key="<NAI_API_KEY>"
)

# Enabling reasoning via thinking parameter
stream = client.chat.completions.create(
  model="llama-3.3-nemotron-super-49b-v1.5",
  messages=[{
    "role": "user",
    "content": "Solve this logic puzzle: If all roses are flowers and some flowers are red, can we conclude that some roses are red?",
  }],
  extra_body={
    "thinking": {"type": "enabled", "budget_tokens": 2048}
  },
  temperature=0.7,
  stream=True
)

for chunk in stream:
  if hasattr(chunk.choices[0].delta, 'reasoning_content') and chunk.choices[0].delta.reasoning_content:
      print(f"[Thinking] {chunk.choices[0].delta.reasoning_content}", end="", flush=True)
  if chunk.choices[0].delta.content:
      print(chunk.choices[0].delta.content, end="", flush=True)
```

#### **Manual Override**

You can also control reasoning via prompt instructions:
- **Enable**: Start system prompt with `/think`.
- **Disable (Default)**: Start system prompt with `/no_think`.

-----

### Specialized Neosantara Models

Neosantara AI provides optimized versions of core models like `nusantara-base` and `archipelago-70b` that are specifically tuned for reasoning. These models use an **Instruction Injection** mechanism to provide step-by-step thinking even on standard chat models.

#### **How it Works**

When you enable reasoning for these models (via `thinking` parameter or `/think`), Neosantara AI automatically appends a system-level instruction (e.g., *"Mohon jelaskan dengan pemikiran langkah demi langkah"*) to your request. This ensures the model breaks down the problem before giving you the final answer.

-----

### Thinking Models (Claude & Gemini)

For models that support native reasoning, such as **Claude 3.5 Sonnet** and **Gemini 2.0 Flash**, Neosantara AI supports the `thinking` parameter. This allows you to allocate a specific token budget for the model's internal thought process.

#### **Using the `thinking` Parameter**

When using the Anthropic-compatible API, you can provide a `thinking` object.

```json icon="code"
{
  "model": "claude-3-haiku",
  "messages": [...],
  "thinking": {
    "type": "enabled",
    "budget_tokens": 2048
  }
}
```

#### **Reasoning Effort Mapping**

If you are using the OpenAI-compatible API, the `thinking` budget is automatically mapped to the `reasoning_effort` parameter based on industry standards:

| `budget_tokens` | `reasoning_effort` |
| :--- | :--- |
| >= 10,000 | `high` |
| >= 5,000 | `medium` |
| >= 2,000 | `low` |
| `< 2,000` | `minimal` |

-----

### Best Practices

To get the best results from Llama 3.3 Nemotron, treat it like an expert problem-solver. Provide a clear, high-level objective and let the model determine the best steps to reach the solution.

- **Strengths**: Excels at open-ended reasoning, multi-step logic, and complex coding or mathematical problems.
- **Avoid Over-prompting**: Micromanaging each step can limit the model's advanced reasoning capabilities. Give it the goal, not the exact path.
- **Provide Clear Objectives**: Ensure your prompt is clear and unambiguous to get the most accurate and relevant response.
- **Use Streaming**: For complex queries, the reasoning process can generate a lot of text. Streaming the response provides a much better user experience.

-----

### Use Cases

- **Code Generation & Analysis:** Analyze large codebases, suggest improvements, and generate complex code snippets.
- **Strategic Planning:** Develop multi-stage plans, reasoning about optimal approaches and potential obstacles.
- **Complex Document Analysis:** Process and summarize technical specifications, legal contracts, and research papers.
- **Agentic Workflows:** Build sophisticated AI agents that can perform complex, multi-step tasks.
- **Scientific Research:** Assist in hypothesis generation, experimental design, and data analysis.
- **Advanced Problem Solving:** Handle ambiguous requirements by inferring unstated assumptions and providing logical solutions.

## Next Steps

- See [our embeddings capability](/en/capability/embeddings)
- see [our image generation capability](/en/capability/image-generation)
- see [our integration](/en/integrations)
