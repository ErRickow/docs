---
title: "Reasoning"
description: "Leverage advanced cognitive capabilities with step-by-step chain-of-thought processing."
---

import { ModelCards } from '/snippets/model-cards.jsx';

Reasoning models are designed to "think" before they speak. Unlike standard chat models that predict the next token immediately, reasoning models generate an internal chain-of-thought to decompose complex instructions, verify facts, and correct their own logic before presenting a final answer.

## The `reasoning_content` Field

Neosantara provides a unified interface for reasoning across all providers. Regardless of whether a model uses native blocks or specific tags (like `<think>`), Neosantara normalizes this output into a dedicated **`reasoning_content`** field in the API response.

---

## How It Works

Neosantara employs three distinct mechanisms to enable reasoning, depending on the model's capabilities.

### 1. Native Reasoning
Models specifically trained for reasoning, such as **DeepSeek-R1**, **Claude 3.7**, and **Gemini 2.0 Flash Thinking**, utilize their built-in logic. Neosantara connects directly to these native "thinking" protocols to ensure the highest quality of thought.

### 2. Instruction Injection
For standard models that don't have native reasoning (e.g., `nusantara-base`, `archipelago-70b`), Neosantara uses **Instruction Injection**. When reasoning is enabled, the system automatically prepends complex logical instructions to the system prompt, forcing the model to break down its process into steps.

### 3. Reasoning Effort & Budgets
For supported models, you can control the "depth" of thought using the `thinking` parameter.

| Budget (Tokens) | Effort Level | Use Case |
| :--- | :--- | :--- |
| < 2,000 | `minimal` | Quick logical checks, simple summaries. |
| 2,000 - 5,000 | `low` | Basic coding tasks, multi-step instructions. |
| 5,000 - 10,000 | `medium` | Complex debugging, creative writing logic. |
| > 10,000 | `high` | Mathematical proofs, architectural planning. |

---

## Enabling Reasoning

You can activate reasoning using the `thinking` configuration object or a manual prompt trigger.

### Via API Parameter (Recommended)

<CodeGroup>

```python OpenAI SDK
response = client.chat.completions.create(
    model="deepseek-r1",
    messages=[{"role": "user", "content": "Solve: 15 * 24 + 133"}],
    extra_body={
        "thinking": { "type": "enabled", "budget_tokens": 2048 }
    }
)

# Access reasoning separately
print(response.choices[0].message.reasoning_content)
print(response.choices[0].message.content)
```

```json JSON Payload
{
  "model": "claude-4.5-sonnet",
  "messages": [...],
  "thinking": {
    "type": "enabled",
    "budget_tokens": 4096
  }
}
```

</CodeGroup>

### Via Manual Trigger
You can also force any chat model into reasoning mode by starting your system prompt with the **`/think`** command. To disable it explicitly, use **`/no_think`**.

---

## Best Practices

1. **Use Streaming**: Reasoning can generate thousands of internal tokens before the final answer appears. Use [Streaming](/en/capability/stream) to provide real-time visual feedback ("Thinking...") to your users.
2. **Be Specific, Not Descriptive**: Give reasoning models clear objectives but avoid micromanaging their steps. Let the model determine the optimal path to the solution.
3. **Budget Wisely**: More reasoning tokens increase latency and cost. Only allocate high budgets (>10k) for truly complex scientific or mathematical tasks.

## Supported Models

<ModelCards capability="reasoning" />
