---
title: "Image Understanding"
description: "Analyze, describe, and extract information from images using multimodal AI models."
---

import { ModelCards } from '/snippets/model-cards.jsx';

Neosantara API supports multimodal capabilities, allowing you to send images along with your text prompts to various AI models. This enables use cases such as describing scenes, identifying objects, reading charts, or extracting handwritten text.

## Supported Models

<ModelCards capability="vision" />

## How to Use

To use image understanding, you provide an array of content parts in your user message, including a part of type `image_url`.

### Using an Image URL

You can provide a publicly accessible link to an image.

<CodeGroup>

```python OpenAI (Python)
from openai import OpenAI

client = OpenAI(
    api_key="YOUR_NSK_KEY",
    base_url="https://api.neosantara.xyz/v1"
)

response = client.chat.completions.create(
    model="claude-4.5-sonnet",
    messages=[
        {
            "role": "user",
            "content": [
                {"type": "text", "text": "What is in this image?"},
                {
                    "type": "image_url",
                    "image_url": {
                        "url": "https://science.nasa.gov/wp-content/uploads/2023/09/web-first-images-release.png",
                    },
                },
            ],
        }
    ],
)

print(response.choices[0].message.content)
```

```javascript OpenAI (Node.js)
import OpenAI from "openai";

const openai = new OpenAI({
  apiKey: "YOUR_NSK_KEY",
  baseURL: "https://api.neosantara.xyz/v1"
});

const response = await openai.chat.completions.create({
  model: "claude-4.5-sonnet",
  messages: [
    {
      role: "user",
      content: [
        { type: "text", text: "What is in this image?" },
        {
          type: "image_url",
          image_url: {
            url: "https://science.nasa.gov/wp-content/uploads/2023/09/web-first-images-release.png",
          },
        },
      ],
    },
  ],
});

console.log(response.choices[0].message.content);
```

</CodeGroup>

### Using Base64 Encoded Images

For local images, you can encode them as Base64 and send them using the `data:` URL scheme.

<CodeGroup>

```python Python
import base64
from openai import OpenAI

def encode_image(image_path):
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode('utf-8')

base64_image = encode_image("path/to/your/image.jpg")

client = OpenAI(api_key="YOUR_NSK_KEY", base_url="https://api.neosantara.xyz/v1")

response = client.chat.completions.create(
    model="claude-4.5-sonnet",
    messages=[
        {
            "role": "user",
            "content": [
                {"type": "text", "text": "Describe this local image."},
                {
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/jpeg;base64,{base64_image}"
                    }
                }
            ]
        }
    ]
)
```

```bash cURL
curl https://api.neosantara.xyz/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_NSK_KEY" \
  -d '{
    "model": "claude-4.5-sonnet",
    "messages": [
      {
        "role": "user",
        "content": [
          { "type": "text", "text": "What is this?" },
          { "type": "image_url", "image_url": { "url": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mP8/5+hHgAHggJ/PchI7wAAAABJRU5ErkJggg==" } }
        ]
      }
    ]
  }'
```

</CodeGroup>

## Supported Image Formats

The Neosantara API supports the following image formats:
*   **JPEG** (`image/jpeg`)
*   **PNG** (`image/png`)
*   **WebP** (`image/webp`)
*   **GIF** (`image/gif`) - Note: Some models may only analyze the first frame.

## Best Practices

1.  **Image Size**: For best results, use images smaller than 5MB. Large images may be automatically resized by the upstream provider.
2.  **Detail Level**: While some models support a `detail` parameter (`low`, `high`, `auto`), most models optimize this automatically.
3.  **Multiple Images**: Most multimodal models support sending multiple images in a single request for comparison or sequential analysis.
