---
title: 'OpenAI Compatibility'
description: 'Use the official OpenAI SDK to interact with Neosantara AI.'
---

Neosantara AI supports the official OpenAI SDK. We offer two distinct API styles to interact with our models. Choose the one that best fits your application architecture.

<Tabs>
  <Tab title="Responses API (Recommended)" icon="bolt">

The **Responses API** (`/v1/responses`) is our modern, unified interface for building powerful, agent-like applications. It simplifies inputs, manages conversation state automatically, and provides native multimodal support.

**Benefits:**

* **Simple Input**: Pass a single string `input` instead of a complex array of message objects.
* **Stateful Context**: Use `store: true` to automatically maintain conversation history on the server.
* **Unified Output**: Consistent output format for text, tools, and reasoning.

### Responses API Quick Start

Use the `client.responses.create` helper (if using a compatible SDK fork) or the generic `client.post` method to access this endpoint.

```python
from openai import OpenAI

client = OpenAI(
    base_url="https://api.neosantara.xyz/v1",
    api_key="<YOUR_API_KEY>"
)

# Generate a response
response = client.responses.create(
    model="nusantara-base",
    input="Write a one-sentence bedtime story about a unicorn.",
    store=True
)

# Access output text directly
print(response.output_text)

# Continue conversation using response ID
print(f"Response ID: {response.id}")
```

```javascript
import OpenAI from "openai";

const openai = new OpenAI({
  baseURL: "https://api.neosantara.xyz/v1",
  apiKey: "<YOUR_API_KEY>",
});

async function main() {
  const response = await openai.responses.create({
    model: "nusantara-base",
    input: "Write a one-sentence bedtime story about a unicorn.",
    store: true
  });

  // Access output text directly
  console.log(response.output_text);
  
  // Continue conversation using ID
  console.log(`Response ID: ${response.id}`);
}

main();
```

```bash
curl https://api.neosantara.xyz/v1/responses \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $NAI_API_KEY" \
  -d '{
    "model": "nusantara-base",
    "input": "Write a one-sentence bedtime story about a unicorn.",
    "store": true
  }'
```

### Responses API Tool Calling

The Responses API simplifies tool use. You can define tools and let the model call them. The output structure cleanly separates tool calls. For a comprehensive guide, see our [Tool Calling documentation](/en/how-tools).

```python
tools = [{
    "type": "function",
    "name": "get_weather",
    "description": "Get current weather",
    "parameters": {
        "type": "object",
        "properties": {
            "location": {"type": "string"}
        },
        "required": ["location"]
    }
}]

response = client.responses.create(
    model="nusantara-base",
    input="What\'s the weather in Jakarta?",
    tools=tools
)

# Iterate through output items to find tool calls
for item in response.output:
    if item.type == "function_call":
        print(f"Tool Call: {item.name} with args {item.arguments}")
```

### Responses API Format

The Responses API returns a `response` object containing an `output` array of items. For full details on the response format, refer to the [Responses API Reference](/api-reference/responses).

```json
{
  "id": "resp_68af4030592c...",
  "object": "response",
  "created_at": 1756315696,
  "model": "nusantara-base",
  "output_text": "Under a quilt of moonlight...",
  "output": [
    {
      "id": "msg_68af...",
      "type": "message",
      "status": "completed",
      "role": "assistant",
      "content": [
        {
          "type": "output_text",
          "text": "Under a quilt of moonlight..."
        }
      ]
    }
  ]
}
```

### Handling Errors

The Responses API uses standard HTTP status codes and detailed error messages. For a complete list of error codes and their meanings, see [API Error Codes](/en/about/errors).

```json
{
  "error": {
    "code": "invalid_request_error",
    "message": "Parameter \'input\' is required.",
    "type": "invalid_request_error"
  }
}
```

### Responses API Support Matrix

| Feature | Status | Note |
| :--- | :---: | :--- |
| **Endpoint** | `/v1/responses` | Dedicated endpoint for stateful interaction |
| **State Management** | ✅ Supported | Managed via `store: true` and `previous_response_id`. See [Conversation Management](/en/conversation-management). |
| **Input Format** | Flexible | Supports `string` or `array` of messages. |
| **Tool Use** | ✅ Enhanced | Supports native tool definitions and execution. |
| **Streaming** | ✅ Supported | Use `stream: true` for SSE. |
| **Legacy Support** | ❌ No | Not compatible with legacy Chat Completion apps without changes |

  </Tab>

  <Tab title="Chat Completions API (Legacy)" icon="message-circle-dots">

The **Chat Completions API** (`/v1/chat/completions`) is fully compatible with the standard OpenAI Chat API. Use this if you are migrating an existing application (e.g., using LangChain, AutoGen) and want to change as little code as possible.

**Characteristics:**

* **Stateless**: You must send the full conversation history (`messages` array) with every request.
* **Standard Format**: Uses the familiar `choices` array structure.
* **Broad Compatibility**: Works out-of-the-box with almost all LLM tools and libraries.

### Chat Completions Quick Start

You can use the standard `client.chat.completions.create` method.

```python
from openai import OpenAI

client = OpenAI(
    base_url="https://api.neosantara.xyz/v1",
    api_key="<YOUR_API_KEY>"
)

completion = client.chat.completions.create(
    model="nusantara-base",
    messages=[
        {"role": "system", "content": "You are a helpful assistant.",},
        {"role": "user", "content": "Hello!"}
    ]
)

print(completion.choices[0].message.content)
```

### Chat Completions Tool Calling

This uses the standard OpenAI format for defining tools and handling function call responses. For a detailed guide on tool use, refer to our [Tool Calling documentation](/en/how-tools).

```python
tools = [{
    "type": "function",
    "function": {
        "name": "get_weather",
        "description": "Get current weather",
        "parameters": {
            "type": "object",
            "properties": {
                "location": {"type": "string"}
            },
            "required": ["location"]
        }
    }
}]

completion = client.chat.completions.create(
    model="nusantara-base",
    messages=[{"role": "user", "content": "What\'s the weather in Jakarta?"}],
    tools=tools
)

tool_calls = completion.choices[0].message.tool_calls
if tool_calls:
    for tc in tool_calls:
        print(f"Function: {tc.function.name}, Args: {tc.function.arguments}")
```

### Chat Completions Format

Returns the standard Chat Completion object. For full details on the response format, refer to the [Chat Completions API Reference](/api-reference/chat/completions/create).

```json
{
  "id": "chatcmpl-C9EDpk...",
  "object": "chat.completion",
  "created": 1756315657,
  "model": "nusantara-base",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "Under a blanket of starlight..."
      },
      "finish_reason": "stop"
    }
  ]
}
```

### Chat Completions Support Matrix

| Feature | Status | Note |
| :--- | :---: | :--- |
| **Endpoint** | `/v1/chat/completions` | Standard OpenAI compatible endpoint |
| **State Management** | ❌ Stateless | Client must manage and send full history |
| **Input Format** | Strict | Requires `messages` array |
| **Tool Use** | ✅ Supported | Standard function calling format. See [Tool Calling Guide](/en/how-tools). |
| **Streaming** | ✅ Supported | Standard SSE format. |
| **Legacy Support** | ✅ Yes | Drop-in replacement for existing OpenAI apps |

  </Tab>
</Tabs>
