---
title: "Llama 3.3 Nemotron Quickstart"
description: "> Get started with Neosantara AIs integration of Llama 3.3 Nemotron, a powerful open reasoning model."
---

This flexible open-weight reasoning model is designed for developers and enterprises who need transparency and customization while maintaining advanced reasoning capabilities for complex tasks.

The Llama 3.3 Nemotron model is highly capable in coding, mathematics, and agentic workflows. By default, Neosantara AI optimizes for speed and cost-efficiency by disabling reasoning. You can explicitly enable it when needed.

### How to Use the API

For reasoning models that produce longer, more detailed responses, we highly recommend streaming tokens to ensure the best user experience.

#### **Default Behavior (Reasoning Off)**

By default, the model will provide a direct answer without the thought process to save tokens and reduce latency.

#### **Enabling Reasoning**

To enable step-by-step reasoning, you can either:
1. Use the **`thinking` parameter** (Recommended for Anthropic/OpenAI SDKs).
2. Add `/think` to the beginning of your **system prompt**.

```python icon="python"
from openai import OpenAI

client = OpenAI(
    base_url="https://api.neosantara.xyz/v1",
    api_key="<YOUR_NEOSANTARA_API_KEY>"
)

# Enabling reasoning via the thinking parameter (mapped to reasoning_effort internally)
stream = client.chat.completions.create(
    model="llama-3.3-nemotron-super-49b-v1.5",
    messages=[
        {
            "role": "user",
            "content": "Solve this logic puzzle: If all roses are flowers and some flowers are red, can we conclude that some roses are red?"
        }
    ],
    extra_body={
        "thinking": {"type": "enabled", "budget_tokens": 2048}
    },
    temperature=0.7,
    stream=True
)

for chunk in stream:
    # Checking for thinking deltas
    if hasattr(chunk.choices[0].delta, 'reasoning_content') and chunk.choices[0].delta.reasoning_content:
        print(f"[Thinking] {chunk.choices[0].delta.reasoning_content}", end="", flush=True)
    if chunk.choices[0].delta.content:
        print(chunk.choices[0].delta.content, end="", flush=True)
```

```typescript
import OpenAI from "openai";

const neosantara = new OpenAI({
  baseURL: "https://api.neosantara.xyz/v1",
  apiKey: "<NAI_API_KEY>",
});

const stream = await neosantara.chat.completions.create({
  model: "llama-3.3-nemotron-super-49b-v1.5",
  messages: [{
    role: "user",
    content: "Solve this logic puzzle: If all roses are flowers and some flowers are red, can we conclude that some roses are red?"
  }],
  // @ts-ignore
  thinking: { type: "enabled", budget_tokens: 2048 },
  temperature: 0.7,
  stream: true,
});

for await (const chunk of stream) {
  // @ts-ignore
  if (chunk.choices[0]?.delta?.reasoning_content) {
     process.stdout.write(`[Thinking] ${chunk.choices[0].delta.reasoning_content}`);
  }
  process.stdout.write(chunk.choices[0]?.delta?.content || "");
}
```

#### **Manual Override**

If you want to manually control reasoning via prompt instructions:
- **Enable**: Start system prompt with `/think`.
- **Disable (Default)**: Start system prompt with `/no_think`.

---

--

### Best Practices

To get the best results from Llama 3.3 Nemotron, treat it like an expert problem-solver. Provide a clear, high-level objective and let the model determine the best steps to reach the solution.

- **Strengths**: Excels at open-ended reasoning, multi-step logic, and complex coding or mathematical problems.
- **Avoid Over-prompting**: Micromanaging each step can limit the model's advanced reasoning capabilities. Give it the goal, not the exact path.
- **Provide Clear Objectives**: Ensure your prompt is clear and unambiguous to get the most accurate and relevant response.
- **Use Streaming**: For complex queries, the reasoning process can generate a lot of text. Streaming the response provides a much better user experience.

---

### Use Cases

- **Code Generation & Analysis:** Analyze large codebases, suggest improvements, and generate complex code snippets.
- **Strategic Planning:** Develop multi-stage plans, reasoning about optimal approaches and potential obstacles.
- **Complex Document Analysis:** Process and summarize technical specifications, legal contracts, and research papers.
- **Agentic Workflows:** Build sophisticated AI agents that can perform complex, multi-step tasks.
- **Scientific Research:** Assist in hypothesis generation, experimental design, and data analysis.
- **Advanced Problem Solving:** Handle ambiguous requirements by inferring unstated assumptions and providing logical solutions.
