---
title: 'Integrations'
description: '> Use Neosantara AI models through partner integrations.'
---

## Vercel AI SDK

*The Vercel AI SDK is a powerful Typescript library designed to help developers build AI-powered applications.*

Install both the Vercel AI SDK and OpenAI's Vercel package.

```shell Shell
npm i ai @ai-sdk/openai
```

Instantiate the Neosantara client and call the generateText function with GPT-5 Mini to generate some text.

```typescript TypeScript icon="square-js"
import { createOpenAICompatible } from '@ai-sdk/openai-compatible';
import { generateText } from 'ai';

const neosantara = createOpenAICompatible({
  name: 'neosantara_xyz',
  apiKey: process.env.NAI_API_KEY ?? "",
  baseURL: 'https://api.neosantara.xyz/v1',
});

const { text } = await generateText({
  model: neosantara('nusantara-base'),
  prompt: 'Write a story about cat want a whiskas',
});

console.log(text)
```

Learn more in our [Neosantara AI - Vercel AI SDK Guide](/en/using-neosantara-with-vercels-ai-sdk).

## LlamaIndex

*LlamaIndex is a simple, flexible data framework for connecting custom data sources to large language models (LLMs).*

Install `llama-index`

```shell Shell
pip install llama-index
```

Here's sample code to get you started with Llama Index + Neosantara AI:

```python Python icon="python"
from llama_index.llms.openai_like import OpenAILike

llm = OpenAILike(
    model="nusantara-base",
    api_base="https://api.neosantara.xyz/v1",
    api_key="NAI_API_KEY",
    is_chat_model=True,
    is_function_calling_model=True,
    temperature=0.1,
)

response = llm.complete("Write up to 500 words essay explaining Large Language Models")

print(response)
```

See [this tutorial blog](/en/llama-index) for the RAG implementation details using Neosantara and LlamaIndex.

## CrewAI

*CrewAI is an open source framework for orchestrating AI agent systems.*

Install `crewai`

```shell Shell
pip install crewai
export NAI_API_KEY=***
```

Build an multi-agent workflow:

```python Python icon="python"
import os
from crewai import LLM, Task, Agent, Crew

llm = LLM(model="openai/nusantara-base",
          api_key=os.environ.get("NAI_API_KEY"),
          base_url="https://api.neosantara.xyz/v1"
        )

research_agent = Agent(
    llm = llm,
    role="Research Analyst",
    goal="Find and summarize information about specific topics",
    backstory="You are an experienced researcher with attention to detail",
    verbose=True  # Enable logging for debugging
)

research_task = Task(
    description="Conduct a thorough research about AI Agents.",
    expected_output="A list with 10 bullet points of the most relevant information about AI Agents",
    agent=research_agent
)

## Execute the crew
crew = Crew(
    agents=[research_agent],
    tasks=[research_task],
    verbose=True
)

result = crew.kickoff()

## Accessing the task output
task_output = research_task.output

print(task_output)
```

Learn more in our [CrewAI guide](/en/crewai).

## PydanticAI

*PydanticAI is an agent framework created by the Pydantic team to simplify building agent workflows.*

Install `pydantic-ai`

```shell Shell
pip install pydantic-ai
export NAI_API_KEY=***
```

Build PydanticAI agents using Neosantara AI models

```python Python icon="python"
from pydantic_ai import Agent
from pydantic_ai.models.openai import OpenAIChatModel
from pydantic_ai.providers.openai import OpenAIProvider

## Connect PydanticAI to LLMs on Neosantara
model = OpenAIChatModel(
    'nusantara-base',
    provider=OpenAIProvider(
        base_url="https://api.neosantara.xyz/v1",
        api_key=os.environ.get("NAI_API_KEY"),
    ),
)

## Setup the agent
agent = Agent(
    model,
    system_prompt='Be concise, reply with one sentence.',
)

result = agent.run_sync('Where does "hello world" come from?')  
print(result.output)
```

Learn more in our [PydanticAI Guide](/en/pydantic-ai)

## Arcade.dev

*Arcade is a platform that lets AI securely use tools like email, files, and APIs to take real actionâ€”not just chat. Build powerful assistants in minutes with ready-to-use integrations or a custom SDK.*

Our guide demonstrates how to integrate Neosantara AI's language models with Arcade's tools to create an AI agent that can send emails.

Prerequisites:

* Neosantara AI API key - see here [https://app.neosantara.xyz/](https://app.neosantara.xyz/api-keys)
* Arcade API key - see here [https://arcade.dev/](https://arcade.dev/)
* Gmail account to connect via OAuth

```shell Shell
## install the required packages
!pip install -qU openai arcadepy
```

Gmail Configuration:

<CodeGroup>
  ```shell Shell icon="terminal"
  import os
  from arcadepy import Arcade
  from openai import OpenAI

  ## Set environment variables
  os.environ["NAI_API_KEY"] = "XXXXXXXXXXXXX"  # Replace with your actual Neosantara API key
  os.environ["ARCADE_API_KEY"] = "arc_XXXXXXXXXXX"    # Replace with your actual Arcade API key

  ## Initialize clients
  nai_client = OpenAI(api_key=os.getenv("NAI_API_KEY"), base_url="https://api.neosantara.xyz/v1")
  arcade_client = Arcade()  # Automatically finds the ARCADE_API_KEY env variable

  ## Set up user ID (your email)
  USER_ID = "your@gmail.com"  # Change this to your email

  ## Authorize Gmail access
  auth_response = arcade_client.tools.authorize(
      tool_name="Google.SendEmail",
      user_id=USER_ID,
  )

  if auth_response.status != "completed":
      print(f"Click this link to authorize: {auth_response.url}")
      # Wait for the authorization to complete
      arcade_client.auth.wait_for_completion(auth_response)

  print("Authorization completed!")
  ```
</CodeGroup>

## DSPy

*DSPy is a framework that enables you to build modular AI systems with code instead of hand-crafted prompting*

Install `dspy`

```shell Shell
pip install -U dspy
export NAI_API_KEY=***
```

Build a question answering agent

```python Python icon="python"
import dspy

#Configure dspy with a LLM from Neosantara AI
lm = dspy.LM('neosantara_ai/archipelago-70b', 
             api_key=os.environ.get("NAI_API_KEY"), 
             api_base="https://api.neosantara.xyz/v1")

#Configure dspy to use the LLM
dspy.configure(lm=lm)

## Gives the agent access to a wikipedia search tool
def search_wikipedia(query: str):
    # Use a more general search or the specific page if known to be reliable
    # For a general search, you might use a different tool or API
    # For this specific case, we stick to the provided URL but simplify the output
    results = dspy.ColBERTv2(url='https://id.m.wikipedia.org/wiki/Prabowo_Subianto')(query, k=1) # Get top 1 result
    # Return the raw text content for the LLM to process
    return results[0]['text'] if results else "No relevant information found."


## setup ReAct module with question and string answer signature
react = dspy.ReAct("question -> answer: str", tools=[search_wikipedia])

pred = react(question="when is prabowo was born?")

print(pred.answer)
```

Learn more in our [DSPy Guide](/en/dspy).

## AutoGen(AG2)

*AG2 (formerly AutoGen) is an open-source framework for building and orchestrating AI agents.*

Install `autogen`

```shell Shell
pip install autogen
export NAI_API_KEY=***
```

Build a coding agent

```python Python icon="python"
import os
from pathlib import Path
from autogen import AssistantAgent, UserProxyAgent
from autogen.coding import LocalCommandLineCodeExecutor

  config_list = [
      {
          # Let's choose the Nusantara-Base model
          "model": "nusantara-base",
          "base_url": "https://api.neosantara.xyz/v1",
          # Provide your Neosantara.xyz API key here or put it into the NAI_API_KEY environment variable.
        "api_key": os.environ.get("NAI_API_KEY"),
          # We specify the API Type as 'openai' so it uses the OpenAI client class
        "api_type": "openai",
        "stream": False,
        "price": [300/1000000*1000, 1500/1000000*1000] # Input: $300/M tokens = $0.3/k tokens, Output: $1500/M tokens = $1.5/k tokens
    }
]

## Setting up the code executor
workdir = Path("coding")
workdir.mkdir(exist_ok=True)
code_executor = LocalCommandLineCodeExecutor(work_dir=workdir)

## Setting up the agents

## The UserProxyAgent will execute the code that the AssistantAgent provides
user_proxy_agent = UserProxyAgent(
    name="User",
    code_execution_config={"executor": code_executor},
    is_termination_msg=lambda msg: "FINISH" in msg.get("content"),
)

system_message = """You are a helpful AI assistant who writes code and the user executes it.
Solve tasks using your coding and language skills.
"""

## The AssistantAgent, using Neosantara's nusantara-base model, will take the coding request and return code
assistant_agent = AssistantAgent(
    name="NAI Coding Assistant",
    system_message=system_message,
    llm_config={"config_list": config_list},
)

## Start the chat, with the UserProxyAgent asking the AssistantAgent the message
chat_result = user_proxy_agent.initiate_chat(
    assistant_agent,
    message="Provide code to count the number of prime numbers from 1 to 10000.",
)
```

Learn more in our [Autogen Guide](/en/autogen).

## Agno

*Agno is an open-source library for creating multimodal agents.*

Install `agno`

```shell Shell
pip install -U agno ddgs
```

Build a search and answer agent

```python Python icon="python"
from agno.agent import Agent
from agno.models.openai.like import OpenAILike
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=OpenAILike(
        id="nusantara-base"
        api_key=os.environ.get("NAI_API_KEY")
        base_url="https://api.neosantara.xyz/v1"
    ),
    tools=[DuckDuckGoTools()],
    markdown=True
)
agent.print_response("What's happening in Indonesia?", stream=True)
```

Learn more in our [Agno Guide](/en/agno).

## Pinecone

*Pinecone is a vector database that helps companies build RAG applications.*

Here's some sample code to get you started with Pinecone + Neosantara AI:

```python Python icon="python"
from pinecone import Pinecone, ServerlessSpec
from openai import OpenAI

pc = Pinecone(
  api_key="PINECONE_API_KEY", 
  source_tag="NEOSANTARA_AI"
)
nai = OpenAI(
    api_key="NAI_API_KEY", 
    base_url="https://api.neosantara.xyz/v1"
)

## Create an index in pinecone
index = pc.create_index(
    name="serverless-index",
    dimension=1536,
    metric="cosine",
    spec=ServerlessSpec(cloud="aws", region="us-west-2"),
)

## Create an embedding on Neosantara AI
textToEmbed = "Our solar system orbits the Milky Way galaxy at about 515,000 mph"
embeddings = nai.embeddings.create(
    model="nusa-embedding-0001", 
  	input=textToEmbed
)

## Use index.upsert() to insert embeddings and index.query() to query for similar vectors
```